{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3c91192",
   "metadata": {},
   "source": [
    "<h1> <center><u> <font color='blue'>Multiple Linear Regression with Python</font></u></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62cbbc3",
   "metadata": {},
   "source": [
    "### Setting up the Working Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a58b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1280dff",
   "metadata": {},
   "source": [
    "### The Working Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c4a13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing boston dataset from sklearn\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15300838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting X and y\n",
    "X = load_boston().data\n",
    "y = load_boston().target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490e20de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfrom X into DataFrame\n",
    "boston = pd.DataFrame(X, columns=load_boston().feature_names)\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c33f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserting the target variable to the DataFrame\n",
    "boston.insert(0, 'Price', y)\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd196fd8",
   "metadata": {},
   "source": [
    "### Using sklearn to build regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5688fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LinearRegression from sklear.linear_model\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2943b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a linear regression object\n",
    "lm_reg = LinearRegression() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd5aed0",
   "metadata": {},
   "source": [
    "### Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87cba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the linear regression model\n",
    "lm_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bc629e",
   "metadata": {},
   "source": [
    "### Checking the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdb644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the intercept value\n",
    "print(\"The model intercept value is {:.4f}\".format(lm_reg.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f4152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zipping coefficients with their names\n",
    "list(zip(boston.columns[1:], lm_reg.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e919c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the parameters \n",
    "for var, coef in list(zip(boston.columns[1:], lm_reg.coef_)):\n",
    "    print(\"The {0:7s} coefficient is: {1:8.4f}\".format(var,coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29aa98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(list(zip(boston.columns[1:], lm_reg.coef_)), \n",
    "             columns=[\"Variable\", \"Coefficient\"])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b63ced",
   "metadata": {},
   "source": [
    "###  Prediction\n",
    "\n",
    "After fitting the model, we can implement the model to predict on new data. In our case, we don't have new data, therefore we predict on the data used to build the model. __predict()__ method of linear regression model does the predition for us.\n",
    "\n",
    "Syntax:\n",
    "```python \n",
    "y_pred = lm_obj.predict(New data)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4757a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "y_pred = lm_reg.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22a572f",
   "metadata": {},
   "source": [
    "## Model Performance\n",
    "\n",
    "After learning how to fit a model, and how to do prediction, you need to a tool to measure the performance of your model. In linear regression problems, we have many metrics, and each metric has its strengths and its weaknesses; however, there are common ones used listed below:\n",
    "\n",
    "### The model Scores\n",
    "\n",
    "  1. R^2 (Coefficient of Determination)\n",
    "  2. MAE (mean squared error)\n",
    "  3. RMSE (Root Mean Squared Error)\n",
    "  \n",
    "These metrics are available in sklearn __metrics__, and to use them we need to import them. \n",
    "\n",
    "Syntax:\n",
    "```python\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "```\n",
    "\n",
    "At this step, we train and predict the model on the same data we trained the model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f762b5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5df10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the R^2\n",
    "print(\"Mean squared error: {:.4f}\".format(r2_score(y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45883b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean squared error\n",
    "print(\"Mean squared error: {:.4f}\".format(mean_squared_error(y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583278e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Root Mean squared Error \n",
    "print(\"Mean squared error: {:.4f}\".format(np.sqrt(mean_squared_error(y, y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73701032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean absolute error\n",
    "print(\"Mean absolute error: {:.4f}\".format(mean_absolute_error(y, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923dd847",
   "metadata": {},
   "source": [
    "# Machine Learning Process\n",
    "\n",
    "Building Machine Learning Models goes through several steps, which we mention here briefly:\n",
    "\n",
    "1. **Step 1**: **Extracting features**: Datasets don't typically come naturally with clear features, so there's work to be done in reformatting the dataset. Additionally, you need to decide what features you want to begin with. \n",
    "\n",
    "2. **Step 2**: **Dataset splitting**: split the dataset into two datasets: the test and train dataset. \n",
    "\n",
    "3. **Step 3: Model Training**: Train the model on training set.\n",
    "\n",
    "4. **Step 4: Model Evaluation**: The model has to be evaluated on the test set. Model evaluation is performed many times, not just once. \n",
    "\n",
    "    - In model evaluation, a threshold based on a calculate metric must be decided to in order to decide whether the model is useful and can be used in practice.\n",
    "    - If the model is not good, we need to move back to training step to __tune__ the model, considering other solutions considering the inputs.\n",
    "    - We go back and forth between building and testing several times until we are satisfied about our model.\n",
    "    - If the model is not improving, maybe because of small dataset, or not enough features ... etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d08681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import Image, HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2fde24",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('ML process.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7c1b26",
   "metadata": {},
   "source": [
    "# Train-Test and Model Validation \n",
    "\n",
    "Using the data to train the model, then assess the model on the same data is not a good idea (__not honest assessment__), and the model's performance will not be indicative of how well it can generalize to unseen data. For this reason, it is common practice to split your data into two sets, a training set and a test set. You train or fit the model on the __training set__. Then you make predictions on the test set. Finally, the metrics will be calculated between the predictions and the known values. \n",
    "\n",
    "## Splitting Data into Train/Test sets\n",
    "\n",
    "  - It is common practice in machine learning project to split the data into __train set__ and __test set__ (also called unseen data). \n",
    "  \n",
    "  - The train set is used to train or fit the model\n",
    "  \n",
    "  - The test set is used to __evaluate or assess__ the model\n",
    "  \n",
    "  \n",
    "\n",
    "### Splitting The Dataset Using sk-learn \n",
    "\n",
    "  - First, import __train_test_split()__ from __sklearn.model selection__.\n",
    "  \n",
    "  - Use the __train_test_split()__ to randomly split the data.\n",
    "  \n",
    "#### __train_test_split()__ has few arguments:\n",
    "   - __*arrays__: This mean you pass first feature data, and the second the target data.\n",
    "   - __test_size__ argument specifies what proportion of the original data is used for the test set (20%, 25%, 30% are common used proportions)\n",
    "   - __random_state__ sets a seed for the random number generator that splits the data into train and test. Setting the seed with the same number allows us to reproduce the exact split so we get the same results. \n",
    "   - __shuffle__ by default is __True__, which shuffles the data to ensure that data is not ordered in any way.\n",
    "   - __stratify__ This is useful in classification problems. __Stratification__ means the same proportion of __events__ and __non-events__ are the same in both train and test sets. (we will use it in comming lectures)\n",
    "   \n",
    "Note:\n",
    "\n",
    "   - By default, __train_test_split()__ splits the data into 75% training data and 25% test data, which is a good rule of thumb.\n",
    "   - The common names for datasets are (__X_train, X_test__ (X is uppercase), __y_train, y_test__ (y is lowercase))\n",
    "\n",
    "Suntax:\n",
    "```python\n",
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test= train_test_split( X, y, \n",
    "                                                   test_size=0.2, \n",
    "                                                   random_state=10123)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585b5197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split from sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cd331e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training and test sets\n",
    "X_train, X_test, y_train, y_test= train_test_split( X, y, \n",
    "                                                   test_size=0.2, \n",
    "                                                   random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5a627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print shapes of the training and testing data sets\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a50fdb",
   "metadata": {},
   "source": [
    "### Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8315edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Linear Regression object\n",
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00110f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model on the training set\n",
    "lm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b38737",
   "metadata": {},
   "source": [
    "### Prediction on training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be41899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on train set\n",
    "pred_train = lm.predict(X_train)\n",
    "# Predict on test set\n",
    "pred_test = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26cbeef",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3570dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The R^2 Score\n",
    "print(\"The R^2 on the train set is: {:.4f}\".format(r2_score(pred_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25844b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The R^2 Score\n",
    "print(\"The R^2 on the test set is: {:.4f}\".format(r2_score(pred_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a921f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The MSE on the train set is: {:.4f}\".\\\n",
    "      format(mean_squared_error(y_train, pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c01071",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The MSE on the test set is: {:.4f}\". \\\n",
    "      format(mean_squared_error(y_test, pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f571db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The RMSE on the train set is: {:.4f}\".\\\n",
    "      format(np.sqrt(mean_squared_error(y_train, pred_train))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bad158",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The RMSE on the test set is: {:.4f}\". \\\n",
    "      format(np.sqrt(mean_squared_error(y_test, pred_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95337836",
   "metadata": {},
   "source": [
    "## Model Diagnostics (Residual Plot)\n",
    "\n",
    "One of the tools of regression analysis diagnostics is __residual plot__. The residuals are the difference between the actual values and the predicted values:\n",
    "$$resid= y - \\hat y$$ or \n",
    "$$residuals = actual \\ \\ values - predicted \\ \\ values$$\n",
    "\n",
    " - **Residual plot**: is a graph that shows the **residuals** on the vertical axis and the **predicted values** on the horizontal axis.\n",
    " \n",
    " \n",
    " - If the points in a residual plot are randomly scattered around the horizontal axis, a linear regression model is appropriate for the data; otherwise, a non-linear model is more appropriate.\n",
    " \n",
    " \n",
    " - If there is some strucutre or pattern, that means your model is not capturing all the variances. There could be an interaction between variables, or time data where the time is not considered. If this is the case, the data must be examined again carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de0fc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the residuals\n",
    "resid_train = y_train - pred_train\n",
    "resid_test = y_test-pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f059ab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot the training data\n",
    "plt.figure(figsize= (12, 6))\n",
    "train = plt.scatter(x = pred_train, y = resid_train , c = 'b', alpha=0.5)\n",
    "\n",
    "# Scatter plot the testing data\n",
    "test = plt.scatter(pred_test, resid_test , c = 'r', alpha=0.5)\n",
    "\n",
    "# Plot a horizontal axis line at 0\n",
    "plt.hlines(y = 0, xmin = -10, xmax = 50)\n",
    "\n",
    "# Labels\n",
    "plt.legend((train, test), ('Training','Test'), loc='upper left')\n",
    "plt.title('Residual Plots')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ec61e9",
   "metadata": {},
   "source": [
    "It seems there is not an abvious pattern in the residual plot, and all the points are plotted above and below the horizontal line. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b68318",
   "metadata": {},
   "source": [
    "## Problems are to be considered:\n",
    "\n",
    "1. The model was tested only once and only a one portion of the data, so, is this the best technique? and is it the efficient technique to test the model?\n",
    "\n",
    "Consider this case: \n",
    "\n",
    "   - If we split the data again to train and test data, are we going to have the same results?\n",
    "\n",
    "2. We assumed the relationship is linear, which might not be the case, shouldn't we consider another non-linear algorithm!. \n",
    "\n",
    "3. We didn't consider any interactions between variables, but there might be some interactions.\n",
    "\n",
    "4. No data transformation has been done. So, if we transform the features, we expect some improvement in the model.\n",
    "\n",
    "\n",
    "All the previous questions should be taken under consideration to improve the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282833fb",
   "metadata": {},
   "source": [
    "## Try to improve the model by coming back the step of building the model. \n",
    "\n",
    "In the next lecture, we will learn how to improve the predictive power of our models by learning new techniques about __tweaking or tuning__ the model's options. \n",
    "\n",
    "### Here are the topics of the next tutorial \n",
    "\n",
    "  1. K-fold Cross-Validation (CV)\n",
    "  \n",
    "  \n",
    "  2. Data Transformation\n",
    "     - Standardization\n",
    "     - Normalization\n",
    "     - Log Transformation\n",
    "     \n",
    "     \n",
    "  3. Hyper-Parameter Tuning\n",
    "  \n",
    "     - Ridge Regression\n",
    "     - Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc162f59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
